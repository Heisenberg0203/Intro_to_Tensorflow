{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  model1 with sgd as optimizer and mean squared error as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 27.6103 - accuracy: 0.0170\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 27.6101 - accuracy: 0.0545\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 27.6101 - accuracy: 0.0636\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6101 - accuracy: 0.06800s - loss: 27.6053 \n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 27.6052 - accuracy: 0.0714- ETA: 0s - loss: 27.6260 - accura - 4s 60us/sample - loss: 27.6101 - accuracy: 0.0714\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6101 - accuracy: 0.0736\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 27.6101 - accuracy: 0.0761\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 27.6101 - accuracy: 0.0772\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 27.6101 - accuracy: 0.0790\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6101 - accuracy: 0.0800\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 27.6101 - accuracy: 0.0806\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6101 - accuracy: 0.0819\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 27.6101 - accuracy: 0.08251s - lo\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 27.6101 - accuracy: 0.0834\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 27.6101 - accuracy: 0.08430s - loss: 27.6106 - accuracy: 0.08\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 27.6101 - accuracy: 0.08471s - loss: 27.6092\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 27.6100 - accuracy: 0.0856\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 27.6100 - accuracy: 0.0860\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6100 - accuracy: 0.0871\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 27.6100 - accuracy: 0.0869\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 27.6100 - accuracy: 0.0876\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6100 - accuracy: 0.08860s - loss: 27.451\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 27.6100 - accuracy: 0.0882\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6100 - accuracy: 0.08940s - loss: 27.5724 - ac\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 27.6100 - accuracy: 0.08931s - loss: 2\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6100 - accuracy: 0.08900s - loss: 27.5874 - accuracy: 0\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 27.6100 - accuracy: 0.08930s - loss: 27.6116 - accuracy: 0\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 27.6073 - accuracy: 0.089 - 3s 58us/sample - loss: 27.6100 - accuracy: 0.0899\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 27.6100 - accuracy: 0.0900\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 27.6100 - accuracy: 0.0897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[27.61004059448242, 0.0957]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                           tf.keras.layers.Dense(256,activation=tf.nn.relu),\n",
    "                           tf.keras.layers.Dense(1024,activation=tf.nn.relu),\n",
    "                           tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'sgd',\n",
    "              loss = 'mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Adam optimizer and sparse_categorical_crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 3.0271 - accuracy: 0.6788\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.6632 - accuracy: 0.7546\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.5574 - accuracy: 0.8018\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.5301 - accuracy: 0.8156\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.5028 - accuracy: 0.8267\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.4962 - accuracy: 0.8294\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4853 - accuracy: 0.8361\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4750 - accuracy: 0.8393\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4756 - accuracy: 0.8401\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4640 - accuracy: 0.8416\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4708 - accuracy: 0.8410s - loss: 0.4727 - accuracy\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4560 - accuracy: 0.8469\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.4576 - accuracy: 0.8457\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4514 - accuracy: 0.8467\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: 0.4533 - accuracy: 0.8481\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.4470 - accuracy: 0.8492\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.4511 - accuracy: 0.8485\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4422 - accuracy: 0.8508\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4558 - accuracy: 0.8490\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4496 - accuracy: 0.8498\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.4378 - accuracy: 0.8555\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.4426 - accuracy: 0.8523\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 9s 153us/sample - loss: 0.4398 - accuracy: 0.8546\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4390 - accuracy: 0.8541\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4457 - accuracy: 0.8516\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4327 - accuracy: 0.8558\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4456 - accuracy: 0.8536\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4421 - accuracy: 0.8553\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.4278 - accuracy: 0.8569\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4444 - accuracy: 0.8557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6281270745754242, 0.8133]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/1.0\n",
    "test_images = test_images/1.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 : With Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.5021 - accuracy: 0.8242\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3765 - accuracy: 0.8645\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3342 - accuracy: 0.8774\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3115 - accuracy: 0.8860\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2952 - accuracy: 0.8908\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2796 - accuracy: 0.8962\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2683 - accuracy: 0.8995\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2567 - accuracy: 0.9049\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2461 - accuracy: 0.9077\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2371 - accuracy: 0.9113\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2296 - accuracy: 0.9128\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2230 - accuracy: 0.9175\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2162 - accuracy: 0.9188\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2098 - accuracy: 0.9214\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2039 - accuracy: 0.9231\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1962 - accuracy: 0.9266\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1920 - accuracy: 0.9284\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1866 - accuracy: 0.9308\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.93 - 5s 80us/sample - loss: 0.1823 - accuracy: 0.9313\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1770 - accuracy: 0.9341\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1731 - accuracy: 0.9358\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1720 - accuracy: 0.9353\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1658 - accuracy: 0.9374\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1619 - accuracy: 0.9392\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1574 - accuracy: 0.9410\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1550 - accuracy: 0.9418\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1506 - accuracy: 0.9442\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1476 - accuracy: 0.9457\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1441 - accuracy: 0.9461\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1386 - accuracy: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40890381172299384, 0.8853]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 : with 512 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.4731 - accuracy: 0.8317\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 9s 148us/sample - loss: 0.3604 - accuracy: 0.8688\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3217 - accuracy: 0.8805\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 10s 158us/sample - loss: 0.2994 - accuracy: 0.8898\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.2795 - accuracy: 0.8966\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.2647 - accuracy: 0.9018\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2525 - accuracy: 0.9065\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2415 - accuracy: 0.9099\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.2307 - accuracy: 0.9118\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.2215 - accuracy: 0.9157\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 9s 155us/sample - loss: 0.2131 - accuracy: 0.9200\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 10s 160us/sample - loss: 0.2041 - accuracy: 0.9240\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 12s 197us/sample - loss: 0.1983 - accuracy: 0.9251\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 0.1907 - accuracy: 0.9280\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: 0.1828 - accuracy: 0.9304\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 11s 181us/sample - loss: 0.1799 - accuracy: 0.9317\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 12s 192us/sample - loss: 0.1712 - accuracy: 0.9358\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.1679 - accuracy: 0.9362\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 9s 149us/sample - loss: 0.1597 - accuracy: 0.9393\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 8s 137us/sample - loss: 0.1573 - accuracy: 0.9408\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 11s 185us/sample - loss: 0.1534 - accuracy: 0.9421\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.1476 - accuracy: 0.9437\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 9s 158us/sample - loss: 0.1412 - accuracy: 0.9465\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 0.1410 - accuracy: 0.9473\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.1347 - accuracy: 0.9481\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.1321 - accuracy: 0.9499\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1288 - accuracy: 0.9512\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.1256 - accuracy: 0.9528\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 0.1236 - accuracy: 0.9535\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.1214 - accuracy: 0.9538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4285091275691986, 0.897]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 11s 191us/sample - loss: 0.4674 - accuracy: 0.8325\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.3545 - accuracy: 0.8699\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 11s 188us/sample - loss: 0.3216 - accuracy: 0.8814\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 11s 183us/sample - loss: 0.2949 - accuracy: 0.8902\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.2784 - accuracy: 0.8967\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.2654 - accuracy: 0.9003\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: 0.2519 - accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.2407 - accuracy: 0.9098\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 11s 188us/sample - loss: 0.2289 - accuracy: 0.9140\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.2226 - accuracy: 0.9162\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.2117 - accuracy: 0.9208\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: 0.2047 - accuracy: 0.9224\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.1961 - accuracy: 0.9259\n",
      "Epoch 14/30\n",
      "17344/60000 [=======>......................] - ETA: 6s - loss: 0.1804 - accuracy: 0.9326"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.4851 - accuracy: 0.8252\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3605 - accuracy: 0.8675\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3272 - accuracy: 0.8785\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3042 - accuracy: 0.8872\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2857 - accuracy: 0.8937\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2712 - accuracy: 0.8984\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2578 - accuracy: 0.9043\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2464 - accuracy: 0.9070\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.2384 - accuracy: 0.9093\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2270 - accuracy: 0.9141\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2207 - accuracy: 0.9165\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2103 - accuracy: 0.9202\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2028 - accuracy: 0.9225\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1965 - accuracy: 0.9253\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1874 - accuracy: 0.9279\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1838 - accuracy: 0.9288\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1776 - accuracy: 0.9319\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1735 - accuracy: 0.9341\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1658 - accuracy: 0.9367\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1622 - accuracy: 0.9380\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1581 - accuracy: 0.9403\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1533 - accuracy: 0.9414\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1497 - accuracy: 0.9423\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1471 - accuracy: 0.9430\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1399 - accuracy: 0.9464\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1364 - accuracy: 0.9479\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1352 - accuracy: 0.9484\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 0.1282 - accuracy: 0.9508\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1273 - accuracy: 0.9511\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.95 - 6s 93us/sample - loss: 0.1251 - accuracy: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4613285664200783, 0.8861]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: In model 4 and model 5, we can see our loss is increasing in middle, there is no point in training the model if your loss is increasing. It is better to stop if your loss hits a specific value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model6 : Using Callbacks on model 4, since it performed better of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "59168/60000 [============================>.] - ETA: 0s - loss: 0.4764"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1136f501711b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m ])\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m                       total_epochs=1)\n\u001b[0;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 372\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    683\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-1136f501711b>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mmyCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m       \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nReached 60% accuracy so cancelling training!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.95):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
